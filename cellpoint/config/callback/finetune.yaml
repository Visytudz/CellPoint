model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: "checkpoints"
  filename: "{epoch:03d}-{val/acc:.4f}"
  monitor: "val/acc"
  mode: "max"
  save_top_k: 3
  save_last: true
  auto_insert_metric_name: false

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: "epoch"

rich_progress_bar:
  _target_: pytorch_lightning.callbacks.RichProgressBar
  refresh_rate: 1