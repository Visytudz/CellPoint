model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: "checkpoints"
  filename: "epoch{epoch:03d}-step{step}-loss{train/loss_epoch:.4f}"
  monitor: "train/loss_epoch"
  mode: "min"
  save_top_k: 3
  save_last: true
  auto_insert_metric_name: false
  save_on_train_epoch_end: true

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: "epoch"

rich_progress_bar:
  _target_: pytorch_lightning.callbacks.RichProgressBar