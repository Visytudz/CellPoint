model_checkpoint:
  _target_: pytorch_lightning.callbacks.ModelCheckpoint
  dirpath: "checkpoints"
  filename: "{epoch:03d}-{step}-{train/loss:.4f}"
  monitor: "train/loss"
  mode: "min"
  save_top_k: 3
  save_last: true
  auto_insert_metric_name: false

lr_monitor:
  _target_: pytorch_lightning.callbacks.LearningRateMonitor
  logging_interval: "epoch"

rich_progress_bar:
  _target_: pytorch_lightning.callbacks.RichProgressBar